{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime Classification\n",
    "\n",
    "From 2010 - 2015 the San Francisco police department made records crime reports from across all of San Francisco's neighborhoods. \n",
    "\n",
    "Our task is **to predict if the crime was theft or not!**\n",
    "\n",
    "![](https://digital.ihg.com/is/image/ihg/holiday-inn-san-francisco-6019097353-2x1)\n",
    "\n",
    "The following information has been recorded in our data: \n",
    "* `Dates` - timestamp of the crime incident\n",
    "* `Category` - category of the crime incident. \n",
    "* `Descript` - detailed description of the crime incident (not available in live data)\n",
    "* `PdDistrict` - name of the Police Department District\n",
    "* `Resolution` - how the crime incident was resolved (not available in live data)\n",
    "* `Address` - the approximate street address of the crime incident\n",
    "* `X` - Longitude\n",
    "* `Y` - Latitude\n",
    "* `Theft` - A flag that states if the crime was a theft or larcency. **This is the target variable you are going to predict.**\n",
    "\n",
    "Our target is **Theft**. Alternatively you can build a model to predict `Category`. This will be a bit harder since there are so many categories of crime.\n",
    "\n",
    "This dataset and the corresponding challenge was part of a competition hosted by Kaggle and many people have attempted to solve this problem before you. Take a look at what people have tried at the [Kaggle site](https://www.kaggle.com/c/sf-crime/notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "Use this next cell to import the libraries you need, pandas is already done for you. If you need more the further down the notebook you get come back and add them to this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow\n",
    "\n",
    "We are going to follow the following project steps:\n",
    "\n",
    "- Import the data\n",
    "- Exploratory Data Analysis\n",
    "- In-depth Data Analysis\n",
    "- Feature Engineering\n",
    "- Preparing the Data for Sci-kit Learn\n",
    "- Use a transformer on categorical features\n",
    "- Build a pipeline\n",
    "- Using grid search on model parameters\n",
    "- Analysing model predictive power\n",
    "- Further improvements\n",
    "- Conclusion/suggestions for future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "First import the data from the `sf_crime_hackathon.csv` in the `/data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "### Part 1: Exploratory Analysis\n",
    "\n",
    "Run some of the following to start to learn about your data:\n",
    "\n",
    "- `df.head()`, `df.tail()`, `df.sample(5)`\n",
    "- `df.shape`\n",
    "- `df.describe()`\n",
    "- `df.info()`\n",
    "- `df.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is everything as you'd expect?\n",
    "\n",
    "You may have noticed that we need to clean our data before we can do any analysis.\n",
    "Re-read the data in and add parameters to `.read_csv()` and chain methods to:\n",
    "- parse the type of the `dates` column\n",
    "- rename the colums to be all lower case (or upper if you prefer)\n",
    "- rename the column `dates` to be `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: In-depth Analysis (with optional visualisations)\n",
    "\n",
    "Answer the following questions and make 2 up of your own to answer. Here you have the option to visualise your results using `.plot()`. \n",
    "\n",
    "1. How many missing values are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many unique values for address are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What are the top 10 largest categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Which month has the most amount of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which district has the most amount of crime? Which has the least?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the 10 most/least occuring crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "New question 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "New question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Now we're going to create some new features for our model. We saw previously that we can create new features from our `date` feature. Create the following columns and drop the original `date` column:\n",
    "- `n_days`: Number of days since first date\n",
    "- `day`: The day of the year\n",
    "- `weekday`: The day of the week\n",
    "- `month`: The month of the year\n",
    "- `year`: The year\n",
    "- `hour`: The hour of the day\n",
    "- `minute`: The minute of the hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the features have been created correctly. What is the max and min of the new features? Is that what you expect?\n",
    "\n",
    "Now let's make some extra features. The address column will be an issue since there are over 22000 unique values. Also we probably want to drop such sensitive data. Instead let's create:\n",
    "- `is_block`: Take the value of True if the `address` feature has the word `Block` in\n",
    "- `x_minus_y`: The difference between `x` and `y`\n",
    "- `x_plus_y`: The sum of `x` and `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any extra features\n",
    "\n",
    "Add at least 2 extra features.\n",
    "\n",
    "Potential features:\n",
    "\n",
    "- Any special date fields\n",
    "- Features based on past observations (e.g. crime in the same area during the past year)\n",
    "- Converting categorical features (`pddistrict`) into numeric using target encoding\n",
    "- Any other combination of features\n",
    "- External features (from other datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to seperate our features and our labels.\n",
    "\n",
    "Note that two features will need to be dropped:\n",
    "- `descript` - detailed description of the crime incident, therefore a more detailed version of our **target feature**\n",
    "- `resolution` - how the crime incident was resolved, therefore created after our target was defined, and cannot be used to predict a new crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X and y. \n",
    "\n",
    "- X should have the following features (plus whatever bespoke ones you've created): \n",
    "```python\n",
    "'pddistrict', 'x', 'y','n_days', 'day', 'dayofweek', 'month', 'year', 'hour', 'minute', 'x_minus_y', 'x_plus_y', 'is_block'\n",
    "```\n",
    "- y should only have one feature: `theft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which features are categorical (`object` data types):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some non-numeric data that we will need to change! (`pddistrict`, `address`)\n",
    "\n",
    "First let's split into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a base-line model\n",
    "\n",
    "Choose a model to build and use the raw data to build a base-line model. Drop all missing rows.\n",
    "\n",
    "How does your model perform? How do other algorithms perform? Why are some better than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "\n",
    "You can use one-hot encoding to convert the categorical features, or just drop them for now while building a baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ColumnTransformer\n",
    "\n",
    "Let's include `ColumnTransformer()` so that we can apply the onehotencoder to only the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline\n",
    "\n",
    "Now that we know we have to transform our data using a sklearn transformer, it would be good to package this up into a pipeline.\n",
    "\n",
    "Let's build a RandomForest to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch\n",
    "\n",
    "Now let's see if we can hypertune these parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "So far we've looked at Accuracy Score, F1-Score, Recall and Precision. Can you create an output that reports these metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Now that you have your model, can you look at the feature importance to reduce the features in your model and still maintain the score?\n",
    "\n",
    "To access the feature importance you must:\n",
    "\n",
    "1. access the model from the pipeline: `pipeline['model']`\n",
    "2. access the feature importances attribute using `.feature_importances_`\n",
    "\n",
    "You can then plot this against the feature names (`.get_feature_names_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the model using fewer characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
